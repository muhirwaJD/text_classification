# ============================================================================
# GRU MODEL IMPLEMENTATION WITH MULTIPLE EMBEDDINGS
# E-commerce Product Classification
# ============================================================================

# %% [markdown]
# # 1. Import Libraries

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, GRU, Bidirectional, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical

from gensim.models import Word2Vec, FastText
import warnings
warnings.filterwarnings('ignore')

print("✓ Libraries imported successfully")
print(f"TensorFlow version: {tf.__version__}")

# %% [markdown]
# # 2. Load Pre-split Data
# 
# Load your pre-split and pre-cleaned train, validation, and test datasets.

# %%
# Load your datasets (adjust paths as needed)
train_df = pd.read_csv('train.csv')  # Replace with your actual path
val_df = pd.read_csv('val.csv')      # Replace with your actual path
test_df = pd.read_csv('test.csv')    # Replace with your actual path

# Assuming columns are 'text' and 'label'
X_train = train_df['text'].values
y_train = train_df['label'].values

X_val = val_df['text'].values
y_val = val_df['label'].values

X_test = test_df['text'].values
y_test = test_df['label'].values

print(f"Training samples: {len(X_train)}")
print(f"Validation samples: {len(X_val)}")
print(f"Test samples: {len(X_test)}")

# %% [markdown]
# # 3. Encode Labels

# %%
# Encode labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_val_encoded = label_encoder.transform(y_val)
y_test_encoded = label_encoder.transform(y_test)

# Convert to categorical
num_classes = len(label_encoder.classes_)
y_train_cat = to_categorical(y_train_encoded, num_classes)
y_val_cat = to_categorical(y_val_encoded, num_classes)
y_test_cat = to_categorical(y_test_encoded, num_classes)

print(f"Number of classes: {num_classes}")
print(f"Classes: {label_encoder.classes_}")

# %% [markdown]
# # 4. Hyperparameters

# %%
# Hyperparameters for e-commerce dataset
MAX_VOCAB_SIZE = 15000
MAX_SEQUENCE_LENGTH = 150
EMBEDDING_DIM = 100

print(f"Max vocabulary size: {MAX_VOCAB_SIZE}")
print(f"Max sequence length: {MAX_SEQUENCE_LENGTH}")
print(f"Embedding dimension: {EMBEDDING_DIM}")

# %% [markdown]
# # 5. Text Tokenization and Sequence Preparation

# %%
# Create tokenizer
tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')
tokenizer.fit_on_texts(X_train)

# Convert to sequences
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_val_seq = tokenizer.texts_to_sequences(X_val)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Pad sequences
X_train_padded = pad_sequences(X_train_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')
X_val_padded = pad_sequences(X_val_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')
X_test_padded = pad_sequences(X_test_seq, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')

vocab_size = min(len(tokenizer.word_index) + 1, MAX_VOCAB_SIZE)

print(f"Vocabulary size: {vocab_size}")
print(f"Sequence shape (train): {X_train_padded.shape}")
print(f"Sample sequence: {X_train_seq[0][:20]}")

# %% [markdown]
# # 6. Tokenization for Word2Vec and FastText

# %%
# Tokenize for Word2Vec and FastText (they need lists of words)
tokenized_train = [text.split() for text in X_train]
tokenized_val = [text.split() for text in X_val]
tokenized_test = [text.split() for text in X_test]

print(f"Sample tokenized text: {tokenized_train[0][:10]}")

# %% [markdown]
# # 7. GRU Model Architecture and Helper Functions

# %%
def create_gru_model(vocab_size, embedding_dim, max_length, num_classes,
                     embedding_matrix=None, trainable_embedding=True):
    """
    Create GRU model for e-commerce classification
    """
    model = Sequential(name='GRU_Ecommerce')
    
    # Embedding layer
    if embedding_matrix is not None:
        model.add(Embedding(
            input_dim=vocab_size,
            output_dim=embedding_dim,
            weights=[embedding_matrix],
            input_length=max_length,
            trainable=trainable_embedding
        ))
    else:
        model.add(Embedding(
            input_dim=vocab_size,
            output_dim=embedding_dim,
            input_length=max_length
        ))
    
    # GRU layers
    model.add(Bidirectional(GRU(128, return_sequences=True)))
    model.add(Dropout(0.3))
    model.add(Bidirectional(GRU(64)))
    model.add(Dropout(0.3))
    
    # Dense layers
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))
    
    return model

def get_callbacks():
    """Training callbacks"""
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True,
        verbose=1
    )
    
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3,
        min_lr=1e-7,
        verbose=1
    )
    
    return [early_stopping, reduce_lr]

def evaluate_model(model, X_test, y_test, y_test_encoded, label_encoder, model_name):
    """Comprehensive model evaluation"""
    y_pred_proba = model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_pred_proba, axis=1)
    
    accuracy = accuracy_score(y_test_encoded, y_pred)
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_test_encoded, y_pred, average='weighted'
    )
    
    cm = confusion_matrix(y_test_encoded, y_pred)
    
    print(f"\n{'='*60}")
    print(f"{model_name} - Test Results")
    print(f"{'='*60}")
    print(f"Accuracy:  {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1-Score:  {f1:.4f}")
    
    # Plot confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_encoder.classes_,
                yticklabels=label_encoder.classes_)
    plt.title(f'Confusion Matrix - {model_name}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()
    
    return {
        'model': model_name,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1
    }

def plot_training_history(history, model_name):
    """Plot training history"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    axes[0].plot(history.history['accuracy'], label='Train Accuracy')
    axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')
    axes[0].set_title(f'{model_name} - Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Accuracy')
    axes[0].legend()
    axes[0].grid(True)
    
    axes[1].plot(history.history['loss'], label='Train Loss')
    axes[1].plot(history.history['val_loss'], label='Val Loss')
    axes[1].set_title(f'{model_name} - Loss')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Loss')
    axes[1].legend()
    axes[1].grid(True)
    
    plt.tight_layout()
    plt.show()

print("✓ Helper functions defined")

# %% [markdown]
# # EXPERIMENT 1: GRU with TF-IDF
# 
# TF-IDF creates document-level features, so we use it with a Dense network rather than GRU for sequential processing.

# %%
print("\n" + "="*60)
print("EXPERIMENT 1: TF-IDF with Dense Neural Network")
print("="*60)

# Vectorize text with TF-IDF
tfidf = TfidfVectorizer(
    max_features=5000,
    ngram_range=(1, 2),
    strip_accents='unicode',
    lowercase=True,
    stop_words='english'
)

X_train_tfidf = tfidf.fit_transform(X_train).toarray()
X_val_tfidf = tfidf.transform(X_val).toarray()
X_test_tfidf = tfidf.transform(X_test).toarray()

print(f"TF-IDF shapes - Train: {X_train_tfidf.shape}, Val: {X_val_tfidf.shape}, Test: {X_test_tfidf.shape}")
print(f"Sparsity: {(X_train_tfidf == 0).sum() / X_train_tfidf.size * 100:.1f}%")

# Build model (Dense NN, not GRU)
model_tfidf = Sequential([
    Dense(256, activation='relu', input_shape=(X_train_tfidf.shape[1],)),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
], name='TF-IDF_DenseNN')

model_tfidf.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nTraining TF-IDF model...")
history_tfidf = model_tfidf.fit(
    X_train_tfidf, y_train_cat,
    validation_data=(X_val_tfidf, y_val_cat),
    epochs=20,
    batch_size=64,
    callbacks=get_callbacks(),
    verbose=1
)

plot_training_history(history_tfidf, 'TF-IDF with Dense NN')

results_tfidf = evaluate_model(
    model_tfidf, X_test_tfidf, y_test_cat,
    y_test_encoded, label_encoder, 'TF-IDF with Dense NN'
)

# %% [markdown]
# # EXPERIMENT 2: GRU with Word2Vec Skip-gram

# %%
print("\n" + "="*60)
print("EXPERIMENT 2: GRU with Word2Vec Skip-gram")
print("="*60)

# Train Word2Vec Skip-gram
print("\nTraining Word2Vec Skip-gram...")
w2v_skipgram = Word2Vec(
    sentences=tokenized_train,
    vector_size=EMBEDDING_DIM,
    window=5,
    min_count=2,
    workers=4,
    sg=1,  # Skip-gram
    epochs=20,
    seed=42
)

print(f"✓ Trained! Vocabulary size: {len(w2v_skipgram.wv)}")

# Create embedding matrix
embedding_matrix_skipgram = np.zeros((vocab_size, EMBEDDING_DIM))
hits, misses = 0, 0

for word, idx in tokenizer.word_index.items():
    if idx < vocab_size:
        try:
            embedding_matrix_skipgram[idx] = w2v_skipgram.wv[word]
            hits += 1
        except KeyError:
            embedding_matrix_skipgram[idx] = np.random.normal(0, 0.1, EMBEDDING_DIM)
            misses += 1

print(f"Embedding coverage: {hits/(hits+misses)*100:.2f}% ({hits}/{hits+misses})")

# Create and train model
model_skipgram = create_gru_model(
    vocab_size=vocab_size,
    embedding_dim=EMBEDDING_DIM,
    max_length=MAX_SEQUENCE_LENGTH,
    num_classes=num_classes,
    embedding_matrix=embedding_matrix_skipgram,
    trainable_embedding=False
)

model_skipgram.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model_skipgram.summary()

print("\nTraining GRU with Skip-gram embeddings...")
history_skipgram = model_skipgram.fit(
    X_train_padded, y_train_cat,
    validation_data=(X_val_padded, y_val_cat),
    epochs=20,
    batch_size=64,
    callbacks=get_callbacks(),
    verbose=1
)

plot_training_history(history_skipgram, 'GRU with Word2Vec Skip-gram')

results_skipgram = evaluate_model(
    model_skipgram, X_test_padded, y_test_cat,
    y_test_encoded, label_encoder, 'GRU with Word2Vec Skip-gram'
)

# %% [markdown]
# # EXPERIMENT 3: GRU with Word2Vec CBOW

# %%
print("\n" + "="*60)
print("EXPERIMENT 3: GRU with Word2Vec CBOW")
print("="*60)

# Train Word2Vec CBOW
print("\nTraining Word2Vec CBOW...")
w2v_cbow = Word2Vec(
    sentences=tokenized_train,
    vector_size=EMBEDDING_DIM,
    window=5,
    min_count=2,
    workers=4,
    sg=0,  # CBOW
    epochs=20,
    seed=42
)

print(f"✓ Trained! Vocabulary size: {len(w2v_cbow.wv)}")

# Create embedding matrix
embedding_matrix_cbow = np.zeros((vocab_size, EMBEDDING_DIM))
hits, misses = 0, 0

for word, idx in tokenizer.word_index.items():
    if idx < vocab_size:
        try:
            embedding_matrix_cbow[idx] = w2v_cbow.wv[word]
            hits += 1
        except KeyError:
            embedding_matrix_cbow[idx] = np.random.normal(0, 0.1, EMBEDDING_DIM)
            misses += 1

print(f"Embedding coverage: {hits/(hits+misses)*100:.2f}% ({hits}/{hits+misses})")

# Create and train model
model_cbow = create_gru_model(
    vocab_size=vocab_size,
    embedding_dim=EMBEDDING_DIM,
    max_length=MAX_SEQUENCE_LENGTH,
    num_classes=num_classes,
    embedding_matrix=embedding_matrix_cbow,
    trainable_embedding=False
)

model_cbow.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nTraining GRU with CBOW embeddings...")
history_cbow = model_cbow.fit(
    X_train_padded, y_train_cat,
    validation_data=(X_val_padded, y_val_cat),
    epochs=20,
    batch_size=64,
    callbacks=get_callbacks(),
    verbose=1
)

plot_training_history(history_cbow, 'GRU with Word2Vec CBOW')

results_cbow = evaluate_model(
    model_cbow, X_test_padded, y_test_cat,
    y_test_encoded, label_encoder, 'GRU with Word2Vec CBOW'
)

# %% [markdown]
# # EXPERIMENT 4: GRU with GloVe
# 
# Download GloVe embeddings from: http://nlp.stanford.edu/data/glove.6B.zip
# Extract and place `glove.6B.100d.txt` in your working directory.

# %%
print("\n" + "="*60)
print("EXPERIMENT 4: GRU with GloVe")
print("="*60)

glove_path = 'glove.6B.100d.txt'  # Adjust path if needed

# Load GloVe embeddings
print("\nLoading GloVe embeddings...")
glove_index = {}

try:
    with open(glove_path, encoding='utf-8') as f:
        for line in f:
            values = line.split()
            word = values[0]
            coefs = np.asarray(values[1:], dtype='float32')
            glove_index[word] = coefs
    
    print(f"✓ Loaded {len(glove_index)} word vectors")
    
    # Create embedding matrix
    embedding_matrix_glove = np.zeros((vocab_size, EMBEDDING_DIM))
    hits, misses = 0, 0
    
    for word, idx in tokenizer.word_index.items():
        if idx < vocab_size:
            embedding_vector = glove_index.get(word)
            if embedding_vector is not None:
                embedding_matrix_glove[idx] = embedding_vector
                hits += 1
            else:
                embedding_matrix_glove[idx] = np.random.normal(0, 0.1, EMBEDDING_DIM)
                misses += 1
    
    print(f"GloVe coverage: {hits/(hits+misses)*100:.2f}% ({hits}/{hits+misses})")
    
    # Create and train model
    model_glove = create_gru_model(
        vocab_size=vocab_size,
        embedding_dim=EMBEDDING_DIM,
        max_length=MAX_SEQUENCE_LENGTH,
        num_classes=num_classes,
        embedding_matrix=embedding_matrix_glove,
        trainable_embedding=False
    )
    
    model_glove.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("\nTraining GRU with GloVe embeddings...")
    history_glove = model_glove.fit(
        X_train_padded, y_train_cat,
        validation_data=(X_val_padded, y_val_cat),
        epochs=20,
        batch_size=64,
        callbacks=get_callbacks(),
        verbose=1
    )
    
    plot_training_history(history_glove, 'GRU with GloVe')
    
    results_glove = evaluate_model(
        model_glove, X_test_padded, y_test_cat,
        y_test_encoded, label_encoder, 'GRU with GloVe'
    )

except FileNotFoundError:
    print(f"⚠️ GloVe file not found at {glove_path}")
    print("Download from: http://nlp.stanford.edu/data/glove.6B.zip")
    results_glove = None

# %% [markdown]
# # EXPERIMENT 5: GRU with FastText

# %%
print("\n" + "="*60)
print("EXPERIMENT 5: GRU with FastText")
print("="*60)

# Train FastText
print("\nTraining FastText...")
fasttext_model = FastText(
    sentences=tokenized_train,
    vector_size=EMBEDDING_DIM,
    window=5,
    min_count=2,
    workers=4,
    sg=1,  # Skip-gram
    epochs=20,
    seed=42
)

print(f"✓ Trained! Vocabulary size: {len(fasttext_model.wv)}")

# Create embedding matrix
embedding_matrix_fasttext = np.zeros((vocab_size, EMBEDDING_DIM))
hits, misses = 0, 0

for word, idx in tokenizer.word_index.items():
    if idx < vocab_size:
        try:
            embedding_matrix_fasttext[idx] = fasttext_model.wv[word]
            hits += 1
        except KeyError:
            embedding_matrix_fasttext[idx] = np.random.normal(0, 0.1, EMBEDDING_DIM)
            misses += 1

print(f"Embedding coverage: {hits/(hits+misses)*100:.2f}% ({hits}/{hits+misses})")

# Create and train model
model_fasttext = create_gru_model(
    vocab_size=vocab_size,
    embedding_dim=EMBEDDING_DIM,
    max_length=MAX_SEQUENCE_LENGTH,
    num_classes=num_classes,
    embedding_matrix=embedding_matrix_fasttext,
    trainable_embedding=False
)

model_fasttext.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nTraining GRU with FastText embeddings...")
history_fasttext = model_fasttext.fit(
    X_train_padded, y_train_cat,
    validation_data=(X_val_padded, y_val_cat),
    epochs=20,
    batch_size=64,
    callbacks=get_callbacks(),
    verbose=1
)

plot_training_history(history_fasttext, 'GRU with FastText')

results_fasttext = evaluate_model(
    model_fasttext, X_test_padded, y_test_cat,
    y_test_encoded, label_encoder, 'GRU with FastText'
)

# %% [markdown]
# # 8. Final Comparison

# %%
print("\n" + "="*80)
print("FINAL COMPARISON - ALL EMBEDDINGS")
print("="*80)

# Collect all results
all_results = [
    results_tfidf,
    results_skipgram,
    results_cbow,
]

if results_glove is not None:
    all_results.append(results_glove)

all_results.append(results_fasttext)

# Create comparison DataFrame
comparison_df = pd.DataFrame(all_results)
comparison_df = comparison_df.sort_values('accuracy', ascending=False)

print("\n" + comparison_df.to_string(index=False))

# Visualize comparison
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Accuracy comparison
axes[0].barh(comparison_df['model'], comparison_df['accuracy'], color='steelblue')
axes[0].set_xlabel('Accuracy', fontsize=12)
axes[0].set_title('Test Accuracy by Embedding Type', fontsize=14, fontweight='bold')
axes[0].set_xlim([0, 1])
for i, v in enumerate(comparison_df['accuracy']):
    axes[0].text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')

# F1 Score comparison
axes[1].barh(comparison_df['model'], comparison_df['f1_score'], color='coral')
axes[1].set_xlabel('F1 Score', fontsize=12)
axes[1].set_title('Test F1 Score by Embedding Type', fontsize=14, fontweight='bold')
axes[1].set_xlim([0, 1])
for i, v in enumerate(comparison_df['f1_score']):
    axes[1].text(v + 0.01, i, f'{v:.4f}', va='center', fontweight='bold')

plt.tight_layout()
plt.savefig('embedding_comparison.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n✓ Comparison visualization saved as 'embedding_comparison.png'")

# %% [markdown]
# # 9. Best Model Analysis

# %%
best_model_name = comparison_df.iloc[0]['model']
best_accuracy = comparison_df.iloc[0]['accuracy']

print("\n" + "="*60)
print("BEST PERFORMING MODEL")
print("="*60)
print(f"Model: {best_model_name}")
print(f"Test Accuracy: {best_accuracy:.4f}")
print(f"Test F1 Score: {comparison_df.iloc[0]['f1_score']:.4f}")
print(f"Test Precision: {comparison_df.iloc[0]['precision']:.4f}")
print(f"Test Recall: {comparison_df.iloc[0]['recall']:.4f}")

# %% [markdown]
# # Summary
# 
# This notebook implemented GRU-based text classification with 5 different embedding techniques:
# 
# 1. **TF-IDF + Dense NN**: Document-level features with feedforward network
# 2. **Word2Vec Skip-gram + GRU**: Context-aware word embeddings with sequential modeling
# 3. **Word2Vec CBOW + GRU**: Faster training, predicts target from context
# 4. **GloVe + GRU**: Pre-trained embeddings capturing global statistics
# 5. **FastText + GRU**: Subword information, handles OOV words better
# 
# Each model was evaluated with:
# - Training/validation learning curves
# - Test accuracy, precision, recall, F1-score
# - Confusion matrices
# - Comparative analysis
